{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a59f80b",
   "metadata": {},
   "source": [
    "This file is used to train risk models. We train 5 risk models for 5 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88255e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "notebook_dir = os.getcwd()\n",
    "print(notebook_dir)\n",
    "os.chdir('./code')\n",
    "from data_preprocess import read_rdata_to_df, stratified_sample\n",
    "from generate_risk_model import RiskModelGenerator\n",
    "os.chdir(notebook_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a58d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_data_blr = pd.read_csv('data/accord_blr.csv')\n",
    "feature_data_f24 = pd.read_csv('data/accord_blr.csv')\n",
    "outcome_data = pd.read_csv('data/accord_outcomes.csv')\n",
    "\n",
    "df = pd.merge(outcome_data, feature_data_blr, on='MaskID', how='inner')\n",
    "df.drop(columns=[\"MaskID\",\"Visit\"], inplace=True)\n",
    "int_cols = ['cvd','female', 'black', 'cvd_hx_baseline', 'smoke',  'bprx', 'statin']\n",
    "df[int_cols] = df[int_cols].apply(lambda x: x.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90424042",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "print(df.columns.to_list())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce0260b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets (70-30 split)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop('cvd', axis=1)\n",
    "y = df['cvd']\n",
    "\n",
    "# this testing set is the validation set used to check the auc of all fitted risk models\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.1, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Training set size:\", len(X_train))\n",
    "print(\"Testing set size:\", len(X_test))\n",
    "print(\"\\nClass distribution:\")\n",
    "print(\"Training set:\", dict(zip(*np.unique(y_train, return_counts=True))))\n",
    "print(\"Testing set:\", dict(zip(*np.unique(y_test, return_counts=True))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43eccd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f72e9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 50 iterations, each time using 20% of the training data\n",
    "n_models = 50\n",
    "for i in range(1, n_models+1):    \n",
    "    X_train_model, _, y_train_model, _ = train_test_split(\n",
    "        X_train, y_train, test_size=0.9, random_state=42+i, stratify=y_train\n",
    "    )\n",
    "\n",
    "    model_generator = RiskModelGenerator()\n",
    "    model_generator.train_models(X_train_model, y_train_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff32b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Dictionary to store results\n",
    "results = {}\n",
    "\n",
    "# Model names and their display names for the plot\n",
    "model_names = {\n",
    "    'logistic_regression': 'Logistic Regression',\n",
    "    'random_forest': 'Random Forest',\n",
    "    'xgboost': 'XGBoost',\n",
    "    'lightgbm': 'LightGBM',\n",
    "    'svm': 'SVM'\n",
    "}\n",
    "\n",
    "# Set up the subplots\n",
    "fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "# Colors for different runs\n",
    "run_colors = ['blue', 'green', 'red', 'purple', 'orange']\n",
    "\n",
    "# Load models and calculate AUC for each model type\n",
    "for idx, (model_name, model_display_name) in enumerate(model_names.items()):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # Plot random classifier line\n",
    "    ax.plot([0, 1], [0, 1], 'k--', label='Random (AUC = 0.500)', alpha=0.5)\n",
    "    \n",
    "    # Process each run for this model\n",
    "    for run in range(1, 6):\n",
    "        run_dir = f'risk_models/run_{run:03d}'\n",
    "        try:\n",
    "            # Load the model\n",
    "            model_path = os.path.join(run_dir, model_name, f'{model_name}.joblib')\n",
    "            model = joblib.load(model_path)\n",
    "            \n",
    "            # Get predictions\n",
    "            y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "            \n",
    "            # Calculate ROC curve and AUC\n",
    "            fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            \n",
    "            # Store results\n",
    "            key = f\"{model_display_name} (Run {run})\"\n",
    "            results[key] = roc_auc\n",
    "            \n",
    "            # Plot ROC curve\n",
    "            ax.plot(fpr, tpr, \n",
    "                   label=f'Run {run} (AUC = {roc_auc:.3f})',\n",
    "                   color=run_colors[run-1],\n",
    "                   alpha=0.8)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {model_name} from run {run}: {str(e)}\")\n",
    "    \n",
    "    # Customize each subplot\n",
    "    ax.set_xlim([0.0, 1.0])\n",
    "    ax.set_ylim([0.0, 1.05])\n",
    "    ax.set_xlabel('False Positive Rate')\n",
    "    ax.set_ylabel('True Positive Rate')\n",
    "    ax.set_title(f'{model_display_name} ROC Curves')\n",
    "    ax.grid(True)\n",
    "    ax.legend(loc='lower right')\n",
    "\n",
    "# Remove the empty subplot\n",
    "axes[-1].remove()\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print sorted results grouped by model type\n",
    "print(\"\\nAUC Scores by Model Type:\")\n",
    "for model_name, model_display_name in model_names.items():\n",
    "    print(f\"\\n{model_display_name}:\")\n",
    "    model_results = {k: v for k, v in results.items() if model_display_name in k}\n",
    "    for key, value in sorted(model_results.items(), key=lambda x: x[1], reverse=True):\n",
    "        print(f\"{key}: {value:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "discco_llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
