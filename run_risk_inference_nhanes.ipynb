{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce20d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "notebook_dir = os.getcwd()\n",
    "print(notebook_dir)\n",
    "os.chdir('./code')\n",
    "from data_preprocess import read_rdata_to_df\n",
    "os.chdir(notebook_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc4a1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdata_file = 'data/nhanes_data.RData'\n",
    "df = read_rdata_to_df(rdata_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad08d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8539349f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select and rename features\n",
    "feature_mapping = {\n",
    "    'FEMALE': 'female',\n",
    "    'AGE': 'baseline_age',\n",
    "    'CVD_HISTORY': 'cvd_hx_baseline',\n",
    "    'BLACK': 'black',\n",
    "    'SMOKE': 'smoke',\n",
    "    'BMI': 'bmi',\n",
    "    'SBP': 'sbp',\n",
    "    'DBP': 'dbp',\n",
    "    'HR': 'hr',\n",
    "    'HBA1C': 'hba1c',\n",
    "    'TCHOL': 'chol',\n",
    "    'LDL': 'ldl',\n",
    "    'HDL': 'hdl',\n",
    "    'TRIG': 'trig',\n",
    "    'FG': 'fpg',\n",
    "    'POTASSIUM': 'potassium',\n",
    "    'SCREAT': 'screat',\n",
    "    'UACR': 'uacr',\n",
    "    'BPRX': 'bprx',\n",
    "    'STATIN': 'statin'\n",
    "}\n",
    "\n",
    "# Select and rename columns\n",
    "df = df[list(feature_mapping.keys())].rename(columns=feature_mapping)\n",
    "print(\"Selected features after renaming:\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "# Display basic statistics for all variables\n",
    "print(\"\\nBasic statistics for all variables:\")\n",
    "print(df.describe().round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef03014d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Dictionary to store all predictions\n",
    "predictions_dict = {}\n",
    "\n",
    "# Model names for loading\n",
    "model_names = {\n",
    "    'logistic_regression': 'Logistic Regression',\n",
    "    'random_forest': 'Random Forest',\n",
    "    'xgboost': 'XGBoost',\n",
    "    'lightgbm': 'LightGBM',\n",
    "    'svm': 'SVM'\n",
    "}\n",
    "\n",
    "# Load models and get predictions\n",
    "for model_name in model_names.keys():\n",
    "    for run in range(1, 51):\n",
    "        try:\n",
    "            # Load the model\n",
    "            run_dir = f'risk_models/run_{run:03d}'\n",
    "            model_path = os.path.join(run_dir, model_name, f'{model_name}.joblib')\n",
    "            model = joblib.load(model_path)\n",
    "            \n",
    "            # Get predictions\n",
    "            y_pred_proba = model.predict_proba(df)[:, 1]\n",
    "            \n",
    "            # Store predictions with model name and run number\n",
    "            col_name = f\"risk_prediction_{model_name}_run{run}\"\n",
    "            predictions_dict[col_name] = y_pred_proba\n",
    "            \n",
    "            print(f\"Successfully loaded and predicted with {model_name} from run {run}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {model_name} from run {run}: {str(e)}\")\n",
    "\n",
    "# Create DataFrame with all predictions\n",
    "risk_predictions = pd.DataFrame(predictions_dict)\n",
    "\n",
    "# Print the shape and first few rows\n",
    "print(\"\\nPredictions DataFrame Shape:\", risk_predictions.shape)\n",
    "print(\"\\nFirst few rows of predictions:\")\n",
    "print(risk_predictions.head())\n",
    "\n",
    "# Basic statistics of predictions\n",
    "print(\"\\nSummary statistics of predictions:\")\n",
    "print(risk_predictions.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbca6c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine original features with risk predictions\n",
    "combined_df = pd.concat([df, risk_predictions], axis=1)\n",
    "\n",
    "# Print info about the combined dataset\n",
    "print(\"Combined DataFrame Shape:\", combined_df.shape)\n",
    "print(\"\\nColumns in combined dataset:\")\n",
    "print(\"Original features:\", df.columns.tolist())\n",
    "print(\"\\nRisk prediction columns:\", risk_predictions.columns.tolist())\n",
    "print(\"\\nFirst few rows of combined dataset:\")\n",
    "print(combined_df.head())\n",
    "\n",
    "# Save the combined dataframe to CSV\n",
    "output_path = os.path.join('data', 'nhanes_data_prediction.csv')\n",
    "combined_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Saved combined dataset to {output_path}\")\n",
    "print(f\"File shape: {combined_df.shape[0]} rows Ã— {combined_df.shape[1]} columns\")\n",
    "print(f\"Contains {len(df.columns)} original features and {len(risk_predictions.columns)} risk prediction columns\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "discco_llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
